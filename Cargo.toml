[package]
name = "llms-from-scratch-rs"
description = "Rust (candle) code for Build a LLM From Scratch by Sebastian Raschka"
version = "0.1.4"
edition = "2021"
repository = "https://github.com/nerdai/llms-from-scratch-rs"
authors = ["Val Andrei Fajardo <andrei@nerdai.io>"]
keywords = ["machine-learning", "llms", "gpt"]
categories = ["science"]
license = "MIT"

exclude = [
    "data/*",
]

[dependencies]
anyhow = "1.0.97"
bytes = "1.10.1"
candle-core = { git = "https://github.com/huggingface/candle.git", version = "0.7.2" }
candle-datasets = { git = "https://github.com/huggingface/candle.git", version = "0.7.2" }
candle-nn = { git = "https://github.com/huggingface/candle.git", version = "0.7.2" }
clap = { version = "4.5.32", features = ["derive"] }
comfy-table = "7.1.4"
fancy-regex = "0.14.0"
hf-hub = "0.4.2"
itertools = "0.14.0"
lexical-core = "1.0.5"
ndarray = "0.16.1"
phf = { version = "0.11.3", features = ["macros"] }
plotly = "0.12.1"
polars = { version = "0.46.0", features = ["csv", "dtype-struct", "lazy", "parquet", "rows"] }
rand = "0.9.0"
reqwest = { version = "0.12.12", features = ["blocking", "json"] }
rstest = "0.25.0"
serde = { version = "1.0.219", features = ["derive"] }
serde_json = "1.0.138"
serde_with = "3.12.0"
sysinfo = "0.33.1"
tempfile = "3.19.0"
tiktoken-rs = "0.6.0"
tokenizers = "0.21.1"
tqdm = "0.7.0"
zip = "2.5.0"

[features]
cuda = ["candle-core/cuda", "candle-nn/cuda"]
