[package]
name = "llms-from-scratch-rs"
description = "Rust (candle) code for Build a LLM From Scratch by Sebastian Raschka"
version = "0.1.5"
edition = "2021"
repository = "https://github.com/nerdai/llms-from-scratch-rs"
authors = ["Val Andrei Fajardo <andrei@nerdai.io>"]
keywords = ["machine-learning", "llms", "gpt"]
categories = ["science"]
license = "MIT"

exclude = [
    "data/*",
]

[dependencies]
anyhow = "1.0.98"
bytes = "1.10.1"
candle-core = { git = "https://github.com/huggingface/candle.git", version = "0.9.1" }
candle-datasets = { git = "https://github.com/huggingface/candle.git", version = "0.9.1" }
candle-nn = { git = "https://github.com/huggingface/candle.git", version = "0.9.1" }
clap = { version = "4.5.40", features = ["derive"] }
comfy-table = "7.1.4"
fancy-regex = "0.14.0"
hf-hub = "0.4.3"
itertools = "0.14.0"
lexical-core = "1.0.5"
ndarray = "0.16.1"
phf = { version = "0.12.1", features = ["macros"] }
plotly = "0.12.1"
polars = { version = "0.49.1", features = ["csv", "dtype-struct", "lazy", "parquet", "rows"] }
rand = "0.9.1"
reqwest = { version = "0.12.22", features = ["blocking", "json"] }
rstest = "0.25.0"
serde = { version = "1.0.219", features = ["derive"] }
serde_json = "1.0.140"
serde_with = "3.13.0"
sysinfo = "0.35.2"
tempfile = "3.20.0"
tiktoken-rs = "0.6.0"
tokenizers = "0.21.2"
tqdm = "0.7.0"
zip = "4.2.0"

[features]
cuda = ["candle-core/cuda", "candle-nn/cuda"]
