[package]
name = "llms-from-scratch-rs"
description = "Rust (candle) code for Build a LLM From Scratch by Sebastian Raschka"
version = "0.1.5"
edition = "2021"
repository = "https://github.com/nerdai/llms-from-scratch-rs"
authors = ["Val Andrei Fajardo <andrei@nerdai.io>"]
keywords = ["machine-learning", "llms", "gpt"]
categories = ["science"]
license = "MIT"

exclude = [
    "data/*",
]

[dependencies]
anyhow = "1.0.100"
bytes = "1.10.1"
candle-core = { git = "https://github.com/huggingface/candle.git", version = "0.9.1" }
candle-datasets = { git = "https://github.com/huggingface/candle.git", version = "0.9.1" }
candle-nn = { git = "https://github.com/huggingface/candle.git", version = "0.9.1" }
clap = { version = "4.5.48", features = ["derive"] }
comfy-table = "7.2.0"
fancy-regex = "0.16.1"
hf-hub = "0.4.3"
itertools = "0.14.0"
lexical-core = "1.0.6"
ndarray = "0.16.1"
phf = { version = "0.13.1", features = ["macros"] }
plotly = "0.12.1"
polars = { version = "0.51.0", features = ["csv", "dtype-struct", "lazy", "parquet", "rows"] }
rand = "0.9.2"
reqwest = { version = "0.12.23", features = ["blocking", "json"] }
rstest = "0.26.1"
serde = { version = "1.0.228", features = ["derive"] }
serde_json = "1.0.145"
serde_with = "3.14.1"
sysinfo = "0.37.0"
tempfile = "3.21.0"
tiktoken-rs = "0.6.0"
tokenizers = "0.22.0"
tqdm = "0.8.0"
zip = "5.1.1"

[features]
cuda = ["candle-core/cuda", "candle-nn/cuda"]
